"""Emergency report generation when agent fails to create one."""

import time

from ..ui.console import console
from ..prompts import load_prompt


def create_emergency_report(question, research_content, partial=False):
    """
    Create a markdown report from available research.

    Args:
        question: The research question
        research_content: Available research findings
        partial: Whether this is a partial/incomplete report

    Returns:
        str: Markdown formatted report
    """
    status = (
        "Partial Research Report" if partial else "Research Report (Auto-Generated)"
    )
    warning = ""

    if partial:
        warning = """
> **Warning**: This report was automatically generated because the research process
> was interrupted or incomplete (recursion limit, timeout, or manual stop).
"""
    else:
        warning = """
> **Note**: This report was automatically generated because the AI agent did not
> create the final report file. The content below was extracted from the agent's research.
"""

    report = f"""# {status}

## Research Question

{question}

## Status

{warning}

## Research Findings

{research_content if research_content.strip() else "*No research content was captured during agent execution.*"}

---

*This report was auto-generated by the deterministic safety net in `run_research()`*
*Generated at: {time.strftime("%Y-%m-%d %H:%M:%S")}*
"""

    return report


def refine_emergency_report_with_llm(
    question: str, raw_findings: str, language: str = "nl"
) -> str | None:
    """
    Use Claude to restructure raw emergency content into a professional report.

    Args:
        question: The original research question
        raw_findings: Raw extracted research content
        language: Language for the report (nl/en)

    Returns:
        Structured markdown report, or None if refinement fails
    """
    from anthropic import Anthropic

    # Skip if no substantial content
    if not raw_findings or len(raw_findings.strip()) < 500:
        return None

    client = Anthropic()

    if language == "nl":
        lang_instruction = """Schrijf in het Nederlands.
BELANGRIJK: Gebruik Nederlandse titel-casing voor koppen (alleen eerste woord met hoofdletter, niet elk woord).
Correct: "De veranderende rol van leiderschap"
Fout: "De Veranderende Rol van Leiderschap" """
    else:
        lang_instruction = (
            "Write in English (use standard English title case for headings)."
        )

    refinement_prompt = load_prompt("emergency_refinement").format(
        lang_instruction=lang_instruction,
        question=question,
        raw_findings=raw_findings[:80000],
    )

    try:
        console.print(
            "\n[bold yellow]Genereren van gestructureerd rapport uit research...[/bold yellow]"
        )
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=12000,
            messages=[{"role": "user", "content": refinement_prompt}],
        )
        refined = response.content[0].text
        console.print("[green]Rapport succesvol gestructureerd met LLM[/green]")
        return refined
    except Exception as e:
        console.print(f"[yellow]LLM refinement failed: {e}, using raw content[/yellow]")
        return None
